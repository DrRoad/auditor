---
title: "Introduction into model audit"
author: "Alicja Gosiewska"
date: "`r Sys.Date()`"
output: 
  html_document:
    number_sections: true
vignette: >
  %\VignetteEngine{knitr::knitr}
  %\VignetteIndexEntry{Introduction into model audit}
  %\usepackage[UTF-8]{inputenc}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(warning = FALSE)
```

This vignette demonstrates how to use the auditor package. 
auditor provides methods for model verification and validation by error analysis. 

Many models, such as random forests and neutral networks are nowadays treated as black boxes. Therefore, there is a lack of theory that describes the behavior of errors in those models. 

Most methods provided in auditor package are model-agnostic, so can be used regardless of knowledge about errors. 

Some of the graphical error analysis methods also have corresponding SCORES, which allow comparison of two models.



# Regression use case - apartments data

To illustrate applications of *auditor* to regression problems we will use an artificial dataset apartments available in the [*DALEX*](https://pbiecek.github.io/DALEX/) package. Our goal is to predict the price per square meter of an apartment based on selected features such as construction year, surface, floor, number of rooms, district. It should be noted that four of these variables are continuous while the fifth one is a categorical one. Prices are given in Euro.

```{r}
library(DALEX)
data("apartments")
head(apartments)
```

# Models

We fit two models:

## Linear model
```{r}
lm_model <- lm(m2.price ~ construction.year + surface + floor + no.rooms + district, data = apartments)
```


## Random forest
```{r}
library("randomForest")
set.seed(59)
rf_model <- randomForest(m2.price ~ construction.year + surface + floor +  no.rooms + district, data = apartments)
```


# Preparation for error analysis
The beginning of each analysis is creation of a `modelAudit` object. It’s an object that can be used to audit a model.

```{r}
library("auditor")

lm_audit <- audit(lm_model, label = "lm")
rf_audit <- audit(rf_model, label = "rf")
```


# Model audit

In this section we give short overview of a visual validation of model errors and show the propositions for the validation scores. Auditor helps to find answers for questions that may be crucial for further analyses.

## Does the model fit data? Is it not missing the information?

### Plotting residuals

Function `plot()` used on modelAudit object returns a **Residuals vs fitted values plot**. 

```{r}
plot(rf_audit)
```

Residuals may be ordered by values any model variable of by fitted values. And both models may be plotted together.
```{r}
plot(rf_audit, lm_audit, variable = "m2.price")
```

In the following sections we will show how to use the `plot()` function to generate another diagnostic plots.


### Autocorrelation

On the Autocorrelation plot there are i-th vs i+1-th residuals. This plot may be useful for checking autocorrelation of residuals.

```{r}
plot(rf_audit, type="Autocorrelation", variable="m2.price")
```

Sometimes it is difficult to compare two models basing only on visualizations. Therefore, we have proposed some scores, which may be useful for choosing a betetr model.
DW score and Runs score are based on Durbin-Watson and Runs test statistics. Details and interpretation of scores are described in `scoreDW()` and `scoreRuns()` functions.

Scores can be calculated with the `scoreDW()` and `scoreRuns()` functions and the `score()` function with argument `score` equals to "DW" or "Runs".

```{r}
score(rf_audit, type ="DW", variable = "m2.price")$score
score(rf_audit, type ="Runs", variable = "m2.price")$score
```

### Autocorrelation Function plot

Autocorrelation Function plot can be used to check randomness of errors. If random, autocorrelations should be near zero for lag separations. If non-random, then autocorrelations will be significantly non-zero. 

```{r}
plot(lm_audit, rf_audit, type="ACF")
```

### Scale Location

This plot shows if residuals are spread equally along the ranges of predictors. 

```{r}
plot(rf_audit, type="ScaleLocation")
```

For comparing 2 models we can use GQ score, which is based on Goldfeld-Quandt test statistic.
This score is computed and described in `scoreGQ()` function.
And may be computed also in `score()` function with argument `score` equals "GQ".

### Half-Normal plots
```{r}
plotHalfNormal(lm_audit)
```




## Which model has better performance?

### Observed vs Predicted

```{r}
plotPrediction(lm_audit, rf_audit)
```


### Residuals Density

```{r}
plotResidDens(lm_audit, rf_audit)
```


###  Regression Error Characteristic (REC) Curve

```{r}
plotREC(lm_audit, rf_audit)
```

### Two-sided ECDF

```{r}
plotTwoSidedECDF(lm_audit, rf_audit)
```


###   Regression Receiver Operating Characteristic (RROC)

```{r}
plotRROC(lm_audit, rf_audit)
```


## How similar models are?

### Model PCA

```{r}
plotModelPCA(lm_audit, rf_audit)
```


### Pairs TODO - change name

```{r}
plotPairs(lm_audit, rf_audit)
```



## Other questions

### Which observations are outlyers?

#### Cook's distances

Cook's distance is used to estimate of the influence of an single observation. It is a tool for identifying observations that may negatively affect the model. 

Data points indicated by Cook's distances are worth checking for validity. Cook's distances may be also used for indicating regions of the design space where it would be good to obtain more observations.

Cook’s Distances are calculated by removing the i-th observation from the data and recalculating the model. It shows how much all the values in the model change when the i-th observation is removed. 

In the case of models of classes other than `lm` and `glm` the distances are computed directly from the definition, so this may take a while.
In this example we will compute them for a linear model. 

We will use the Prestige dataset from package car.

```{r}
plot(lm_audit, type="Cook")
```



#Other methods

Here will be described `plotLIFT()`, `plotCGains()`, `plotROC()`
